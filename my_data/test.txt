import os
from concurrent.futures import ThreadPoolExecutor
from typing import List, Dict, Union, Optional
from azure.storage.blob import BlobServiceClient

_blob_service_client_cache: Optional[BlobServiceClient] = None

def initialize_blob_client(
    storage_account_name: str, 
    storage_key: str
) -> BlobServiceClient:
    """Initialize or get existing Azure Blob Service Client."""
    global _blob_service_client_cache
    if _blob_service_client_cache is None:
        connection_string = f"DefaultEndpointsProtocol=https;AccountName={storage_account_name};AccountKey={storage_key};EndpointSuffix=core.windows.net"
        _blob_service_client_cache = BlobServiceClient.from_connection_string(connection_string)
        print("Created a new BlobServiceClient instance.")
    else:
        print("Reusing existing BlobServiceClient instance.")
    return _blob_service_client_cache

def upload_single_blob(
    local_file_path: str,
    local_repo_path: str,
    blob_service_client: BlobServiceClient,
    container_name: str,
    destination_folder: str,
    max_file_size: Optional[int] = None
) -> Dict[str, Optional[str]]:
    """Upload a single file to Azure Blob Storage."""
    result = {
        "file_path": local_file_path,
        "file_relative_path": None,
        "upload_status": "fail",
        "blob_path": None,
        "blob_url": None,
        "error": None
    }
    
    try:
        if not os.path.exists(local_file_path):
            result["error"] = f"File does not exist: {local_file_path}"
            return result
            
        if max_file_size is not None:
            file_size = os.path.getsize(local_file_path)
            if file_size > max_file_size:
                result["error"] = f"File exceeds maximum size limit of {max_file_size/1024/1024:.2f}MB"
                return result
            
        file_relative_path = os.path.relpath(local_file_path, local_repo_path)
        result["file_relative_path"] = file_relative_path

        blob_path = os.path.join(destination_folder, file_relative_path)
        result["blob_path"] = blob_path

        blob_client = blob_service_client.get_blob_client(container=container_name, blob=blob_path)
        blob_client.upload_blob(local_file_path, overwrite=True)

        result["upload_status"] = "success"
        result["blob_url"] = blob_client.url
    except Exception as e:
        result["error"] = str(e)
    return result

def upload_blobs_parallel(
    file_paths: List[str],
    local_repo_path: str,
    storage_account_name: str,
    storage_key: str,
    container_name: str,
    destination_folder: str,
    num_workers: int = 5,
    max_file_size: Optional[int] = None
) -> List[Dict[str, Optional[str]]]:
    """Upload multiple files to Azure Blob Storage in parallel."""
    blob_service_client = initialize_blob_client(storage_account_name, storage_key)

    results = []
    with ThreadPoolExecutor(max_workers=num_workers) as executor:
        futures = [
            executor.submit(upload_single_blob, file_path, local_repo_path, blob_service_client, 
                          container_name, destination_folder, max_file_size)
            for file_path in file_paths
        ]
        for future in futures:
            results.append(future.result())

    return results
