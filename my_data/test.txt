"""Azure Storage File Upload Module.

This module provides functionality to upload files to Azure Blob Storage with support for
parallel uploads, size limits, and progress tracking.
"""

import os
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Dict, Union, Optional
from azure.storage.blob import BlobServiceClient

_blob_service_client_cache: Optional[BlobServiceClient] = None

def initialize_blob_client(
    storage_account_name: str,  # Azure storage account name
    storage_key: str,          # Azure storage account access key
) -> BlobServiceClient:
    """Initialize or retrieve cached Azure Blob Service Client.

    Returns:
        BlobServiceClient: Instance for Azure Blob operations
    """
    global _blob_service_client_cache
    if _blob_service_client_cache is None:
        connection_string = f"DefaultEndpointsProtocol=https;AccountName={storage_account_name};AccountKey={storage_key};EndpointSuffix=core.windows.net"
        _blob_service_client_cache = BlobServiceClient.from_connection_string(connection_string)
        print("Created a new BlobServiceClient instance.")
    else:
        print("Reusing existing BlobServiceClient instance.")
    return _blob_service_client_cache

def upload_single_blob(
    local_file_path: str,      # Full path to local file
    local_repo_path: str,      # Base path of local repository
    blob_service_client: BlobServiceClient,  # Azure blob service client
    container_name: str,       # Azure storage container name
    destination_folder: str,   # Target folder in blob storage
    max_file_size: Optional[int] = None  # Maximum allowed file size in bytes
) -> Dict[str, Optional[str]]:
    """Upload single file to Azure Storage.

    Returns:
        Dict with following keys:
            file_path (str): Original file path
            file_relative_path (str): Path relative to repo
            upload_status (str): "success" or "fail"
            blob_path (str): Path in blob storage
            blob_url (str): Full URL to blob
            error (str): Error message if failed
    """
    result = {
        "file_path": local_file_path,
        "file_relative_path": None,
        "upload_status": "fail",
        "blob_path": None,
        "blob_url": None,
        "error": None
    }
    
    try:
        if not os.path.exists(local_file_path):
            result["error"] = f"File does not exist: {local_file_path}"
            return result
            
        if max_file_size is not None:
            file_size = os.path.getsize(local_file_path)
            if file_size > max_file_size:
                result["error"] = f"File exceeds maximum size limit of {max_file_size/1024/1024:.2f}MB"
                return result
            
        file_relative_path = os.path.relpath(local_file_path, local_repo_path)
        result["file_relative_path"] = file_relative_path

        blob_path = os.path.join(destination_folder, file_relative_path)
        result["blob_path"] = blob_path

        blob_client = blob_service_client.get_blob_client(container=container_name, blob=blob_path)
        blob_client.upload_blob(local_file_path, overwrite=True)

        result["upload_status"] = "success"
        result["blob_url"] = blob_client.url
    except Exception as e:
        result["error"] = str(e)
    return result

def upload_files_to_azure_storage(
    file_paths: List[str],     # List of file paths to upload
    local_repo_path: str,      # Base path of local repository
    storage_account_name: str, # Azure storage account name 
    storage_key: str,         # Azure storage account key
    container_name: str,      # Azure container name
    destination_folder: str,  # Destination folder in Azure Storage
    num_workers: int = 5,    # Number of parallel upload workers
    max_file_size: Optional[int] = None  # Maximum allowed file size in bytes
) -> List[Dict[str, Optional[str]]]:
    """Upload multiple files to Azure Storage with progress tracking.
    
    Returns:
        List of dicts with upload status for each file. Dict format same as upload_single_blob.
        Also prints progress updates and final statistics during execution.
    """
    blob_service_client = initialize_blob_client(storage_account_name, storage_key)
    total_files = len(file_paths)
    completed_files = 0
    results = []

    print(f"\nStarting upload of {total_files} files...")
    
    with ThreadPoolExecutor(max_workers=num_workers) as executor:
        futures = {
            executor.submit(
                upload_single_blob, 
                file_path, 
                local_repo_path, 
                blob_service_client, 
                container_name, 
                destination_folder, 
                max_file_size
            ): file_path for file_path in file_paths
        }
        
        for future in as_completed(futures):
            result = future.result()
            results.append(result)
            completed_files += 1
            
            # Calculate success rate
            success_count = sum(1 for r in results if r["upload_status"] == "success")
            
            # Update progress
            print(f"\rProgress: {completed_files}/{total_files} files processed "
                  f"({success_count} successful, {completed_files - success_count} failed)", 
                  end="", flush=True)

    # Final statistics
    success_count = sum(1 for r in results if r["upload_status"] == "success")
    fail_count = total_files - success_count
    success_rate = (success_count / total_files) * 100 if total_files > 0 else 0
    
    print(f"\n\nUpload completed:")
    print(f"Total files: {total_files}")
    print(f"Successful: {success_count}")
    print(f"Failed: {fail_count}")
    print(f"Success rate: {success_rate:.2f}%")

    return results

if __name__ == "__main__":
    # Example 1: Basic usage
    results = upload_files_to_azure_storage(
        file_paths=["/data/files/document1.pdf"],
        local_repo_path="/data/files",
        storage_account_name="mystorageaccount",
        storage_key="storage-key-123",
        container_name="mycontainer",
        destination_folder="uploads/2024"
    )

    # Example 2: Multiple files with size limit
    file_paths = [f"/data/files/file_{i}.txt" for i in range(1, 101)]
    results = upload_files_to_azure_storage(
        file_paths=file_paths,
        local_repo_path="/data/files",
        storage_account_name="mystorageaccount",
        storage_key="storage-key-123",
        container_name="mycontainer",
        destination_folder="uploads/2024",
        num_workers=10,
        max_file_size=5 * 1024 * 1024  # 5MB limit
    )

"""
Example Output:

Starting upload of 100 files...
Progress: 45/100 files processed (42 successful, 3 failed)
Progress: 100/100 files processed (95 successful, 5 failed)

Upload completed:
Total files: 100
Successful: 95
Failed: 5
Success rate: 95.00%
"""
