import os
from concurrent.futures import ThreadPoolExecutor
from typing import List, Dict, Union, Optional
from azure.storage.blob import BlobServiceClient

_blob_service_client_cache: Optional[BlobServiceClient] = None

def initialize_blob_client(
    storage_account_name: str, 
    storage_key: str
) -> BlobServiceClient:
    """Initialize or get existing Azure Blob Service Client.
    
    Args:
        storage_account_name (str): Azure storage account name
        storage_key (str): Azure storage account access key
    
    Returns:
        BlobServiceClient: Azure blob service client instance
    """
    global _blob_service_client_cache
    if _blob_service_client_cache is None:
        connection_string = f"DefaultEndpointsProtocol=https;AccountName={storage_account_name};AccountKey={storage_key};EndpointSuffix=core.windows.net"
        _blob_service_client_cache = BlobServiceClient.from_connection_string(connection_string)
        print("Created a new BlobServiceClient instance.")
    else:
        print("Reusing existing BlobServiceClient instance.")
    return _blob_service_client_cache

def upload_single_blob(
    local_file_path: str,
    local_repo_path: str,
    blob_service_client: BlobServiceClient,
    container_name: str,
    destination_folder: str,
    max_file_size: Optional[int] = None
) -> Dict[str, Optional[str]]:
    """Upload a single file to Azure Blob Storage.
    
    Args:
        local_file_path (str): Full path to local file
        local_repo_path (str): Base path of local repository
        blob_service_client (BlobServiceClient): Azure blob service client
        container_name (str): Azure storage container name
        destination_folder (str): Target folder in blob storage
        max_file_size (Optional[int]): Maximum allowed file size in bytes
    
    Returns:
        Dict[str, Optional[str]]: Upload status containing:
            file_path: Original file path
            file_relative_path: Path relative to repo
            upload_status: Upload status ("success"/"fail")
            blob_path: Path in blob storage
            blob_url: Full URL to blob
            error: Error message if failed
    """
    result = {
        "file_path": local_file_path,
        "file_relative_path": None,
        "upload_status": "fail",
        "blob_path": None,
        "blob_url": None,
        "error": None
    }
    
    try:
        if not os.path.exists(local_file_path):
            result["error"] = f"File does not exist: {local_file_path}"
            return result
            
        if max_file_size is not None:
            file_size = os.path.getsize(local_file_path)
            if file_size > max_file_size:
                result["error"] = f"File exceeds maximum size limit of {max_file_size/1024/1024:.2f}MB"
                return result
            
        file_relative_path = os.path.relpath(local_file_path, local_repo_path)
        result["file_relative_path"] = file_relative_path

        blob_path = os.path.join(destination_folder, file_relative_path)
        result["blob_path"] = blob_path

        blob_client = blob_service_client.get_blob_client(container=container_name, blob=blob_path)
        blob_client.upload_blob(local_file_path, overwrite=True)

        result["upload_status"] = "success"
        result["blob_url"] = blob_client.url
    except Exception as e:
        result["error"] = str(e)
    return result

def upload_files_to_azure_storage(
    file_paths: List[str],
    local_repo_path: str,
    storage_account_name: str,
    storage_key: str,
    container_name: str,
    destination_folder: str,
    num_workers: int = 5,
    max_file_size: Optional[int] = None
) -> List[Dict[str, Optional[str]]]:
    """Upload multiple files to Azure Blob Storage in parallel.
    
    Args:
        file_paths (List[str]): List of file paths to upload
        local_repo_path (str): Base path of local repository
        storage_account_name (str): Azure storage account name
        storage_key (str): Azure storage account access key
        container_name (str): Azure storage container name
        destination_folder (str): Target folder in blob storage
        num_workers (int, optional): Number of parallel workers. Defaults to 5.
        max_file_size (Optional[int], optional): Maximum allowed file size in bytes. Defaults to None.
    
    Returns:
        List[Dict[str, Optional[str]]]: List of upload status dictionaries for each file
    """
    blob_service_client = initialize_blob_client(storage_account_name, storage_key)

    results = []
    with ThreadPoolExecutor(max_workers=num_workers) as executor:
        futures = [
            executor.submit(upload_single_blob, file_path, local_repo_path, blob_service_client, 
                          container_name, destination_folder, max_file_size)
            for file_path in file_paths
        ]
        for future in futures:
            results.append(future.result())

    return results

# Example Usage
if __name__ == "__main__":
    # Example 1: Upload files with no size limit
    results = upload_files_to_azure_storage(
        file_paths=[
            "/data/files/document1.pdf",
            "/data/files/image1.jpg"
        ],
        local_repo_path="/data/files",
        storage_account_name="mystorageaccount",
        storage_key="storage-key-123",
        container_name="mycontainer",
        destination_folder="uploads/2024"
    )
    
    # Expected output for successful upload:
    # [{
    #     "file_path": "/data/files/document1.pdf",
    #     "file_relative_path": "document1.pdf",
    #     "upload_status": "success",
    #     "blob_path": "uploads/2024/document1.pdf",
    #     "blob_url": "https://mystorageaccount.blob.core.windows.net/mycontainer/uploads/2024/document1.pdf",
    #     "error": None
    # }]

    # Example 2: Upload with 5MB size limit
    results = upload_files_to_azure_storage(
        file_paths=["/data/files/large_file.zip"],
        local_repo_path="/data/files",
        storage_account_name="mystorageaccount",
        storage_key="storage-key-123",
        container_name="mycontainer",
        destination_folder="uploads/2024",
        max_file_size=5 * 1024 * 1024  # 5MB
    )
    
    # Expected output for failed upload (file too large):
    # [{
    #     "file_path": "/data/files/large_file.zip",
    #     "file_relative_path": None,
    #     "upload_status": "fail",
    #     "blob_path": None,
    #     "blob_url": None,
    #     "error": "File exceeds maximum size limit of 5.00MB"
    # }]
