from pyspark.sql import SparkSession
from pyspark.sql.types import StructType, StructField, StringType, TimestampType
from pyspark.sql.functions import col, lit, to_timestamp
from typing import List, Dict
from delta.tables import DeltaTable
import common_utils  # For get_standarized_timestamp

# Define constant for table name at the top
FILE_METADATA_TABLE = "vfs.target_file_metadata"

# Initialize Spark session outside the function
spark = SparkSession.builder.getOrCreate()

# Define schema for target_files DataFrame - without file_path
TARGET_FILES_SCHEMA = StructType([
    StructField("file_relative_path", StringType(), False),
    StructField("git_blob_hash", StringType(), False),
    StructField("category", StringType(), False),
    StructField("file_name", StringType(), True),
    StructField("file_extension", StringType(), True)
])

def merge_target_file_metadata(target_files: List[Dict[str, str]]) -> bool:
    """
    Merge target files into the target_file_metadata Delta table using Delta Lake MERGE operation
    """
    try:
        # Get current timestamp as ISO string
        current_time = common_utils.get_standarized_timestamp()
        current_time = to_timestamp(lit(current_time))
        
        # Create DataFrame from target_files - will ignore file_path if present
        target_df = spark.createDataFrame(target_files, schema=TARGET_FILES_SCHEMA)
        
        # Add current_time column
        target_df = target_df.withColumn("current_time", current_time)
        
        # Get Delta table
        delta_table = DeltaTable.forName(spark, FILE_METADATA_TABLE)
        
        # Execute merge operation
        merge_operation = delta_table.alias("target").merge(
            source=target_df.alias("source"),
            condition="target.file_relative_path = source.file_relative_path"
        ).whenMatchedUpdate(
            condition="target.git_blob_hash != source.git_blob_hash",
            set={
                "git_blob_hash": "source.git_blob_hash",
                "file_status": lit("pending_update"),
                "etl_updated_at": "source.current_time"
            }
        ).whenNotMatchedInsert(
            values={
                "file_relative_path": "source.file_relative_path",
                "git_blob_hash": "source.git_blob_hash",
                "file_status": lit("pending_upload"),
                "etl_created_at": "source.current_time",
                "etl_updated_at": "source.current_time",
                "category": "source.category",
                "file_name": "source.file_name",
                "file_extension": "source.file_extension"
            }
        ).whenNotMatchedBySource(
            set={
                "file_status": lit("pending_delete"),
                "etl_updated_at": "source.current_time"
            }
        )
        
        # Execute the merge
        merge_operation.execute()
        
        # Get operation metrics
        history = delta_table.history(1).collect()[0]
        num_inserted = history["operationMetrics"].get("numTargetRowsInserted", 0)
        num_updated = history["operationMetrics"].get("numTargetRowsUpdated", 0)
        num_deleted = history["operationMetrics"].get("numTargetRowsDeleted", 0)
        
        print(f"Merge operation completed:")
        print(f" - Files inserted (pending_upload): {num_inserted}")
        print(f" - Files updated (pending_update/delete): {num_updated}")
        print(f" - Files deleted: {num_deleted}")
        
        return True
        
    except Exception as e:
        print(f"Error during merge operation: {str(e)}")
        raise

# Example usage
def main():
    # Example target_files - file_path will be ignored by schema
    target_files = [
        {
            'file_path': 'base/path/path/to/file1.txt',  # This will be ignored
            'file_relative_path': 'path/to/file1.txt',
            'git_blob_hash': 'xyz789',
            'category': 'new_docs',
            'file_name': 'file1.txt',
            'file_extension': 'txt'
        },
        {
            'file_path': 'base/path/path/to/file2.py',  # This will be ignored
            'file_relative_path': 'path/to/file2.py',
            'git_blob_hash': 'def456',
            'category': 'scripts',
            'file_name': 'file2.py',
            'file_extension': 'py'
        }
    ]
    
    success = merge_target_file_metadata(target_files)
    if success:
        print("Merge completed successfully")
