from pyspark.sql import SparkSession
from pyspark.sql.functions import concat, lit

# Initialize Spark session (if not already initialized)
spark = SparkSession.builder.appName("FilePaths").getOrCreate()

# Define the root path
root_path = "/path/to/root/"

# Read the table into a DataFrame
df = spark.table("vfs_raw.file_metadata")

# Augment the file_relative_path with the root_path to create full file paths
df = df.withColumn("file_path", concat(lit(root_path), df["file_relative_path"]))

# Select the file_path column and convert it to a list
file_paths_list = df.select("file_path").rdd.flatMap(lambda x: x).collect()

# Display the list of full file paths
print(file_paths_list)
