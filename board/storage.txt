-- Create database if it doesn't exist
CREATE DATABASE IF NOT EXISTS vfs_raw;

-- Create the file_metadata table in the vfs_raw database with a custom location
CREATE TABLE IF NOT EXISTS vfs_raw.file_metadata (
    file_name STRING COMMENT 'Name of the file',
    file_relative_path STRING COMMENT 'Relative path of the file in the repository',
    file_extension STRING COMMENT 'File extension (e.g., md, txt, pdf)',
    category STRING COMMENT 'Category or type of the file (e.g., research_findings)',
    git_last_commit_date TIMESTAMP COMMENT 'Timestamp of the last Git commit for the file',
    git_blob_hash STRING COMMENT 'Git blob hash (unique identifier for the file content)',
    upload_status STRING COMMENT 'Status of the file upload (e.g., pending, needs_reupload, uploaded)',
    upload_on TIMESTAMP COMMENT 'Timestamp when the file was uploaded to Azure',
    blob_url STRING COMMENT 'URL of the file in Azure Blob Storage',
    error_message STRING COMMENT 'Error message if the file upload failed',
    etl_created_at TIMESTAMP COMMENT 'Timestamp when the record was created in the Delta table',
    etl_updated_at TIMESTAMP COMMENT 'Timestamp when the record was last updated in the Delta table'
)
LOCATION 'vfs/raw/metadata';

from pyspark.sql import SparkSession
from pyspark.sql.types import StructType, StructField, StringType, TimestampType
from pyspark.sql.functions import col, lit, when
from datetime import datetime
import pytz
from typing import List, Dict

def first_time_load_file_metadata_to_table(
    metadata_list: List[Dict],
    timezone: str = "America/New_York"
) -> None:
    """
    Load file metadata into vfs_raw.file_metadata Delta table using overwrite mode.
    
    Args:
        metadata_list (List[Dict]): List of dictionaries containing file metadata.
                                  Required fields: file_name, file_relative_path, file_extension,
                                  category, git_blob_hash, upload_status
                                  Optional fields: upload_on, blob_url, error_message
        timezone (str): Timezone for timestamps. Defaults to "America/New_York"
    """
    # Get spark session
    spark = SparkSession.builder.appName("FirstTimeLoadMetadata").getOrCreate()
    
    # Define schema
    schema = StructType([
        StructField("file_name", StringType(), nullable=False),
        StructField("file_relative_path", StringType(), nullable=False),
        StructField("file_extension", StringType(), nullable=False),
        StructField("category", StringType(), nullable=False),
        StructField("git_blob_hash", StringType(), nullable=False),
        StructField("upload_status", StringType(), nullable=False),
        StructField("upload_on", StringType(), nullable=True),
        StructField("blob_url", StringType(), nullable=True),
        StructField("error_message", StringType(), nullable=True)
    ])
    
    # Create initial dataframe
    initial_df = spark.createDataFrame(metadata_list, schema=schema)
    
    # Get current timestamp
    current_time = get_standardized_timestamp(timezone)
    
    # Process dataframe
    processed_df = initial_df \
        .withColumn("upload_on", 
                   when(col("upload_on").isNotNull(),
                        lit(convert_to_standard_timestamp(
                            col("upload_on"), 
                            timezone=timezone)))
                   .otherwise(None)) \
        .withColumn("etl_created_at", lit(current_time)) \
        .withColumn("etl_updated_at", lit(current_time))
    
    # Write to delta table
    processed_df.write.format("delta") \
        .mode("overwrite") \
        .saveAsTable("vfs_raw.file_metadata")
    
    print("First-time load of metadata into Delta table completed successfully.")

if __name__ == "__main__":
    # Example usage
    metadata_list = [
        {
            "file_name": "example.csv",
            "file_relative_path": "data/example.csv",
            "file_extension": "csv",
            "category": "raw_data",
            "git_blob_hash": "abc123",
            "upload_status": "pending",
            "upload_on": None,
            "blob_url": None,
            "error_message": None
        },
        {
            "file_name": "test.json",
            "file_relative_path": "data/test.json",
            "file_extension": "json",
            "category": "raw_data",
            "git_blob_hash": "def456",
            "upload_status": "completed",
            "upload_on": "2024-01-26T10:00:00Z",
            "blob_url": "https://example.com/blob/def456",
            "error_message": None
        }
    ]
    
    # Load metadata
    first_time_load_file_metadata_to_table(metadata_list)
