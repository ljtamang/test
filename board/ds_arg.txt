from pathlib import Path
from typing import Dict, Any, List, Optional
import re
import os
import requests
import time
from concurrent.futures import ThreadPoolExecutor
from collections import defaultdict

# Configuration
MIN_CONTENT_LENGTH = 20  # Minimum words to consider
MIN_PLAN_SCORE = 5
MIN_FINDINGS_SCORE = 6
MIN_GUIDE_SCORE = 5
MAX_WORKERS = 20
REQUEST_DELAY = 0.1
GITHUB_BASE_URL = "https://raw.githubusercontent.com/department-of-veterans-affairs/va.gov-team/refs/heads/master/"

# Caching
content_cache = {}
github_content_cache = {}
stats = defaultdict(int)

def normalize_filename(filename: str) -> str:
    """
    Normalize filename for consistent checking.
    
    Args:
        filename: Input filename to be normalized
    
    Returns:
        Normalized filename with consistent formatting
    """
    filename = Path(filename).stem.lower()
    filename = re.sub(r'[^a-z0-9]', '_', filename)
    filename = re.sub(r'_+', '_', filename)
    return filename.strip('_')

def read_file_content(file_path: str) -> Optional[str]:
    """
    Reads content of a file. Implementation depends on file type.
    
    Args:
        file_path: Path to the file
        
    Returns:
        String content of file if successful, None if reading fails
    """
    if file_path in content_cache:
        return content_cache[file_path]
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
            content_cache[file_path] = content
            return content
    except Exception as e:
        print(f"Failed to read {file_path}: {e}")
        return None

def fetch_github_content(file_path: str) -> Optional[str]:
    """
    Fetch file content from GitHub with caching and retries.
    
    Args:
        file_path: Path to the GitHub file to fetch
        
    Returns:
        String content of the file if successful, None if fetching fails
    """
    if file_path in github_content_cache:
        return github_content_cache[file_path]
    
    full_url = GITHUB_BASE_URL + file_path
    
    for attempt in range(3):
        try:
            time.sleep(REQUEST_DELAY)
            response = requests.get(full_url, timeout=10)
            if response.status_code == 200:
                github_content_cache[file_path] = response.text
                return response.text
        except Exception as e:
            if attempt == 2:
                print(f"Failed to fetch {file_path} after 3 attempts")
                return None
            time.sleep(1)
    return None

def is_valid_content(content: str) -> bool:
    """
    Check if content meets minimum requirements for processing.
    
    Args:
        content: Text content to validate
        
    Returns:
        Boolean indicating if content is valid (meets minimum length)
    """
    return content and len(content.split()) >= MIN_CONTENT_LENGTH

def tag_as_research_plan(file_path: str, min_threshold: int = MIN_PLAN_SCORE) -> Optional[Dict[str, Any]]:
    """
    Tag files as research plans with enhanced scoring.
    
    Args:
        file_path: Path to the file to be tagged
        min_threshold: Minimum score required to tag as a research plan
    
    Returns:
        Dictionary with tag information if file meets criteria, None otherwise
    """
    penalty_keywords = {'guide', 'findings', 'report', 'summary'}
    priority_keywords = [
        'research-plan', 'research_plan', 'researchplan', 'research plan', 
        'uat-plan', 'research_plan_', 'research-plan-', 'researchplan_'
    ]
    
    filename = normalize_filename(Path(file_path).name)
    score = 0
    
    # Penalty check
    for kw in penalty_keywords:
        if kw in filename:
            score -= 8
            break
    
    # Priority filename patterns
    if any(p in filename for p in priority_keywords):
        score += 10
    
    # Content analysis
    content = read_file_content(file_path)
    if content and is_valid_content(content):
        content_lower = content.lower()
        
        # Penalize findings/guide content
        if any(kw in content_lower for kw in ['# findings', '# conversation guide']):
            score -= 5
        
        # Reward plan content
        plan_headers = [
            "## background", "## research goals", "## methodology", 
            "## recruitment", "## timeline", "## team roles"
        ]
        for header in plan_headers:
            if header in content_lower:
                score += 2
                break
        
        if "research plan for" in content_lower:
            score += 5
    
    # Path analysis
    path_str = normalize_filename(str(Path(file_path).parent))
    if "research" in path_str and "plan" in path_str:
        score += 3
    
    if score >= min_threshold:
        return {'tag': 'research_plan', 'score': score}
    return None

def tag_as_research_findings(file_path: str, min_threshold: int = MIN_FINDINGS_SCORE) -> Optional[Dict[str, Any]]:
    """
    Tag files as research findings with enhanced scoring.
    
    Args:
        file_path: Path to the file to be tagged
        min_threshold: Minimum score required to tag as research findings
    
    Returns:
        Dictionary with tag information if file meets criteria, None otherwise
    """
    penalty_keywords = {'plan', 'guide', 'readme'}
    priority_keywords = [
        'research-findings', 'research_findings', 'researchfindings',
        'research findings', 'findings', 'result', 'results'
    ]
    
    filename = normalize_filename(Path(file_path).name)
    score = 0
    
    # Penalty check
    for kw in penalty_keywords:
        if kw in filename:
            score -= 8
            break
    
    # Priority filename patterns
    if any(p in filename for p in priority_keywords):
        score += 10
    
    # Content analysis
    content = read_file_content(file_path)
    if content and is_valid_content(content):
        content_lower = content.lower()
        
        # Penalize plan/guide content
        if any(kw in content_lower for kw in ['# research plan', '# conversation guide']):
            score -= 5
        
        # Reward findings content
        findings_headers = [
            "# research findings", "## key findings",
            "# findings", "## recommendations"
        ]
        for header in findings_headers:
            if header in content_lower:
                score += 2
                break
        
        if "key findings" in content_lower and "recommendations" in content_lower:
            score += 6
    
    # Path analysis
    path_str = normalize_filename(str(Path(file_path).parent))
    if "research" in path_str and "findings" in path_str:
        score += 3
    
    if score >= min_threshold:
        return {'tag': 'research_findings', 'score': score}
    return None

def tag_as_guide(file_path: str, min_threshold: int = MIN_GUIDE_SCORE) -> Optional[Dict[str, Any]]:
    """
    Tag files as conversation guides with enhanced scoring.
    
    Args:
        file_path: Path to the file to be tagged
        min_threshold: Minimum score required to tag as a conversation guide
    
    Returns:
        Dictionary with tag information if file meets criteria, None otherwise
    """
    penalty_keywords = {'plan', 'findings', 'report'}
    priority_keywords = [
        'conversation-guide', 'convo-guide', 'conversation_guide',
        'convo_guide', 'interview-guide', 'discussion-guide'
    ]
    
    filename = normalize_filename(Path(file_path).name)
    score = 0
    
    # Penalty check
    for kw in penalty_keywords:
        if kw in filename:
            score -= 8
            break
    
    # Priority filename patterns
    if any(p in filename for p in priority_keywords):
        score += 10
    
    # Content analysis
    content = read_file_content(file_path)
    if content and is_valid_content(content):
        content_lower = content.lower()
        
        # Penalize plan/findings content
        if any(kw in content_lower for kw in ['# research plan', '# findings']):
            score -= 5
        
        # Reward guide content
        guide_headers = [
            "# conversation guide", "## warm-up questions",
            "## task completion", "## thank you and closing"
        ]
        for header in guide_headers:
            if header in content_lower:
                score += 2
                break
        
        if "conversation guide" in content_lower:
            score += 7
    
    # Path analysis
    path_str = normalize_filename(str(Path(file_path).parent))
    if "research" in path_str and ("interview" in path_str or "usability" in path_str):
        score += 1
    
    if score >= min_threshold:
        return {'tag': 'conversation_guide', 'score': score}
    return None

def keyword_based_tagging(file_path: str) -> Dict[str, Any]:
    """
    Tags files by sequentially applying different tagging strategies.
    Tries to tag as research finding first, then research plan, then guide, then other types.
    
    Args:
        file_path: Path to the file to be tagged
        
    Returns:
        Dictionary containing tag information and score
    """
    content = read_file_content(file_path)
    if not content or not is_valid_content(content):
        return {
            'tag': 'invalid_content',
            'score': 0
        }
    
    # First try to tag as research findings
    tag = tag_as_research_findings(file_path)
    if tag:
        return tag
    
    # If not a research finding, try to tag as research plan
    tag = tag_as_research_plan(file_path)
    if tag:
        return tag
    
    # If not a research plan, try to tag as conversation guide
    tag = tag_as_guide(file_path)
    if tag:
        return tag
    
    # If neither, mark as unclassified
    return {
        'tag': 'unclassified',
        'score': 1
    }

def tag_files(file_paths: List[str]) -> List[Dict[str, Any]]:
    """
    Main function to process and tag multiple files.
    
    Args:
        file_paths: List of paths to files that need to be tagged
        
    Returns:
        List of dictionaries containing detailed tagging information for each file
    """
    tagged_files = []
    
    for file_path in file_paths:
        if not os.path.exists(file_path):
            print(f"Warning: File not found - {file_path}")
            continue
        
        file_tags = {
            'file_path': file_path,
            'tags': [keyword_based_tagging(file_path)]  # Wrap in list to maintain consistent structure
        }
        tagged_files.append(file_tags)
    
    return tagged_files

def test_accuracy(test_files_dir: str) -> Dict[str, Any]:
    """
    Test classification accuracy by reading test file paths from text files and fetching content from GitHub.
    
    Args:
        test_files_dir: Directory containing the test files (plan_paths.txt, findings_paths.txt, guide_paths.txt)
        
    Returns:
        Dictionary containing accuracy results for each category
    """
    # Read test file paths
    def read_test_paths(filename):
        try:
            with open(os.path.join(test_files_dir, filename), 'r') as f:
                return [line.strip() for line in f if line.strip()]
        except FileNotFoundError:
            print(f"Warning: Test file {filename} not found")
            return []
    
    plan_paths = read_test_paths("plan_paths.txt")
    findings_paths = read_test_paths("findings_paths.txt")
    guide_paths = read_test_paths("guide_paths.txt")
    
    # Classify files and check accuracy
    def test_category(file_paths, expected_type):
        correct = 0
        total = 0
        results = []
        
        def process_file(file_path):
            nonlocal correct, total
            content = fetch_github_content(file_path)
            if not content:
                return
            
            # Create a temporary function to return the GitHub content
            def temp_read_file(_):
                return content
            
            # Save original function
            original_read = read_file_content
            try:
                # Temporarily override read_file_content
                globals()['read_file_content'] = temp_read_file
                
                tag = keyword_based_tagging(file_path)
                expected_tag = f"research_{expected_type}" if expected_type != 'guide' else 'conversation_guide'
                results.append({
                    'file_path': file_path,
                    'expected': expected_tag,
                    'actual': tag['tag'],
                    'correct': tag['tag'] == expected_tag
                })
                
                if tag['tag'] == expected_tag:
                    correct += 1
                total += 1
            finally:
                # Restore original function
                globals()['read_file_content'] = original_read
        
        # Process files in parallel
        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            executor.map(process_file, file_paths)
        
        return {
            'total_files': len(file_paths),
            'valid_files': total,
            'correct': correct,
            'accuracy': correct / total * 100 if total > 0 else 0,
            'results': results
        }
    
    # Run tests for each category
    plan_results = test_category(plan_paths, 'plan')
    findings_results = test_category(findings_paths, 'findings')
    guide_results = test_category(guide_paths, 'guide')
    
    total_valid = plan_results['valid_files'] + findings_results['valid_files'] + guide_results['valid_files']
    total_correct = plan_results['correct'] + findings_results['correct'] + guide_results['correct']
    
    return {
        'research_plans': plan_results,
        'research_findings': findings_results,
        'conversation_guides': guide_results,
        'overall_accuracy': total_correct / total_valid * 100 if total_valid > 0 else 0,
        'stats': {
            'total_files': plan_results['total_files'] + findings_results['total_files'] + guide_results['total_files'],
            'valid_files': total_valid,
            'correct': total_correct
        }
    }

# Example Usage
if __name__ == "__main__":
    # Example 1: Tag local files
    local_files = [
        "path/to/research_plan1.md",
        "path/to/findings1.md",
        "path/to/guide1.md",
        "path/to/unknown



# Modified test_accuracy function to match the provided filenames
def test_accuracy(test_files_dir: str) -> Dict[str, Any]:
    """
    Test classification accuracy by reading test file paths from text files and fetching content from GitHub.
    
    Args:
        test_files_dir: Directory containing the test files (plan_path.txt, findings_path.txt, guide_path.txt)
        
    Returns:
        Dictionary containing accuracy results for each category
    """
    # Read test file paths
    def read_test_paths(filename):
        try:
            with open(os.path.join(test_files_dir, filename), 'r') as f:
                return [line.strip() for line in f if line.strip()]
        except FileNotFoundError:
            print(f"Warning: Test file {filename} not found")
            return []
    
    plan_paths = read_test_paths("plan_path.txt")
    findings_paths = read_test_paths("findings_path.txt")
    guide_paths = read_test_paths("guide_path.txt")
    
    # Rest of the function remains the same...
    # [Previous implementation continues]
