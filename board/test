deepseek


from pathlib import Path
from typing import Dict, Any, List, Optional
import re
import os

# Configuration
MIN_CONTENT_LENGTH = 20  # Minimum words to consider
MIN_PLAN_SCORE = 5
MIN_FINDINGS_SCORE = 6
MIN_GUIDE_SCORE = 5

def normalize_filename(filename: str) -> str:
    """Normalize filename for consistent checking"""
    filename = Path(filename).stem.lower()
    filename = re.sub(r'[^a-z0-9]', '_', filename)
    filename = re.sub(r'_+', '_', filename)
    return filename.strip('_')

def read_file_content(file_path: str) -> Optional[str]:
    """Read file content from local file system"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
    except Exception as e:
        print(f"Failed to read {file_path}: {e}")
        return None

def is_valid_content(content: str) -> bool:
    """Check if content meets minimum requirements"""
    return content and len(content.split()) >= MIN_CONTENT_LENGTH

def tag_as_research_plan(file_path: str, min_threshold: int = MIN_PLAN_SCORE) -> Optional[Dict[str, Any]]:
    """Tag files as research plans with enhanced scoring"""
    penalty_keywords = {'guide', 'findings', 'report', 'summary'}
    priority_keywords = [
        'research-plan', 'research_plan', 'researchplan', 'research plan', 
        'uat-plan', 'research_plan_', 'research-plan-', 'researchplan_'
    ]
    
    filename = normalize_filename(Path(file_path).name)
    score = 0
    
    # Penalty check
    for kw in penalty_keywords:
        if kw in filename:
            score -= 8
            break
    
    # Priority filename patterns
    if any(p in filename for p in priority_keywords):
        score += 10
    
    # Content analysis
    content = read_file_content(file_path)
    if content and is_valid_content(content):
        content_lower = content.lower()
        
        # Penalize findings/guide content
        if any(kw in content_lower for kw in ['# findings', '# conversation guide']):
            score -= 5
        
        # Reward plan content
        plan_headers = [
            "## background", "## research goals", "## methodology", 
            "## recruitment", "## timeline", "## team roles"
        ]
        for header in plan_headers:
            if header in content_lower:
                score += 2
                break
        
        if "research plan for" in content_lower:
            score += 5
    
    # Path analysis
    path_str = normalize_filename(str(Path(file_path).parent))
    if "research" in path_str and "plan" in path_str:
        score += 3
    
    if score >= min_threshold:
        return {'tag': 'research_plan', 'score': score}
    return None

def tag_as_research_findings(file_path: str, min_threshold: int = MIN_FINDINGS_SCORE) -> Optional[Dict[str, Any]]:
    """Tag files as research findings with enhanced scoring"""
    penalty_keywords = {'plan', 'guide', 'readme'}
    priority_keywords = [
        'research-findings', 'research_findings', 'researchfindings',
        'research findings', 'findings', 'result', 'results'
    ]
    
    filename = normalize_filename(Path(file_path).name)
    score = 0
    
    # Penalty check
    for kw in penalty_keywords:
        if kw in filename:
            score -= 8
            break
    
    # Priority filename patterns
    if any(p in filename for p in priority_keywords):
        score += 10
    
    # Content analysis
    content = read_file_content(file_path)
    if content and is_valid_content(content):
        content_lower = content.lower()
        
        # Penalize plan/guide content
        if any(kw in content_lower for kw in ['# research plan', '# conversation guide']):
            score -= 5
        
        # Reward findings content
        findings_headers = [
            "# research findings", "## key findings",
            "# findings", "## recommendations"
        ]
        for header in findings_headers:
            if header in content_lower:
                score += 2
                break
        
        if "key findings" in content_lower and "recommendations" in content_lower:
            score += 6
    
    # Path analysis
    path_str = normalize_filename(str(Path(file_path).parent))
    if "research" in path_str and "findings" in path_str:
        score += 3
    
    if score >= min_threshold:
        return {'tag': 'research_findings', 'score': score}
    return None

def tag_as_guide(file_path: str, min_threshold: int = MIN_GUIDE_SCORE) -> Optional[Dict[str, Any]]:
    """Tag files as conversation guides with enhanced scoring"""
    penalty_keywords = {'plan', 'findings', 'report'}
    priority_keywords = [
        'conversation-guide', 'convo-guide', 'conversation_guide',
        'convo_guide', 'interview-guide', 'discussion-guide'
    ]
    
    filename = normalize_filename(Path(file_path).name)
    score = 0
    
    # Penalty check
    for kw in penalty_keywords:
        if kw in filename:
            score -= 8
            break
    
    # Priority filename patterns
    if any(p in filename for p in priority_keywords):
        score += 10
    
    # Content analysis
    content = read_file_content(file_path)
    if content and is_valid_content(content):
        content_lower = content.lower()
        
        # Penalize plan/findings content
        if any(kw in content_lower for kw in ['# research plan', '# findings']):
            score -= 5
        
        # Reward guide content
        guide_headers = [
            "# conversation guide", "## warm-up questions",
            "## task completion", "## thank you and closing"
        ]
        for header in guide_headers:
            if header in content_lower:
                score += 2
                break
        
        if "conversation guide" in content_lower:
            score += 7
    
    # Path analysis
    path_str = normalize_filename(str(Path(file_path).parent))
    if "research" in path_str and ("interview" in path_str or "usability" in path_str):
        score += 1
    
    if score >= min_threshold:
        return {'tag': 'conversation_guide', 'score': score}
    return None

def keyword_based_tagging(file_path: str) -> Dict[str, Any]:
    """
    Tags files by sequentially applying different tagging strategies.
    Tries to tag as research finding first, then research plan, then guide, then other types.
    
    Args:
        file_path: Path to the file to be tagged
        
    Returns:
        Dictionary containing tag information and score
    """
    content = read_file_content(file_path)
    if not content or not is_valid_content(content):
        return {
            'tag': 'invalid_content',
            'score': 0
        }
    
    # First try to tag as research findings
    tag = tag_as_research_findings(file_path)
    if tag:
        return tag
    
    # If not a research finding, try to tag as research plan
    tag = tag_as_research_plan(file_path)
    if tag:
        return tag
    
    # If not a research plan, try to tag as conversation guide
    tag = tag_as_guide(file_path)
    if tag:
        return tag
    
    # If neither, mark as unclassified
    return {
        'tag': 'unclassified',
        'score': 1
    }

def tag_files(file_paths: List[str]) -> List[Dict[str, Any]]:
    """Main function to process and tag multiple files.
    
    Args:
        file_paths: List of paths to files that need to be tagged
        
    Returns:
        List of dictionaries containing detailed tagging information for each file
    """
    tagged_files = []
    
    for file_path in file_paths:
        if not os.path.exists(file_path):
            print(f"Warning: File not found - {file_path}")
            continue
        
        file_tags = {
            'file_path': file_path,
            'tags': [keyword_based_tagging(file_path)]  # Wrap in list to maintain consistent structure
        }
        tagged_files.append(file_tags)
    
    return tagged_files

# Example Usage
if __name__ == "__main__":
    # Example file paths
    files = [
        "path/to/research_plan1.md",
        "path/to/findings1.md",
        "path/to/guide1.md",
        "path/to/unknown_file.txt"
    ]
    
    # Tag the files
    tag_result = tag_files(files)
    
    # Print results
    for result in tag_result:
        print(f"File: {result['file_path']}")
        for tag in result['tags']:  # Still using list iteration for consistency
            print(f"  Tag: {tag['tag']} (Score: {tag['score']})")
